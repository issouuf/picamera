import cv2 as cv
from cv2 import aruco
import numpy as np
from cv2 import Rodrigues 

matrix2kcam = np.array([[878.95170188, 0, 993.89589179],
                        [0           ,876.72068118, 775.53981922],
                        [0           ,0           ,1           ]])
coeff2kcam = np.array([[-0.29467958 , 0.08874286 , 0.00187015, -0.00062744, -0.01134761]])


#camera_matrix = np.array([[275.48494487, 0, 307.36023929],
#                         [0, 274.19034322, 248.29371074],
#                         [0, 0, 1]])  
#dist_coeffs = np.array([-0.32576806, 0.13293918, 0.00102543, -0.00083957, -0.02834439])
camera_matrix = matrix2kcam
dist_coeffs = coeff2kcam

marker_dict = cv.aruco.getPredefinedDictionary(aruco.DICT_4X4_50)
#param_markers = aruco.DetectorParameters_create() #sur la tour et le raspberry pi
param_markers = cv.aruco.DetectorParameters() #sur le pc portable
detector = cv.aruco.ArucoDetector(marker_dict, param_markers)



taillemarker = 0.1 # en mètre







pipeline = " ! ".join(["v4l2src device=/dev/video0",
                       "video/x-raw, width=640, height=480, framerate=30/1",
                       "videoconvert",
                       "video/x-raw, format=(string)BGR",
                       "appsink"
                       ])


h264_pipeline = " ! ".join(["v4l2src device=/dev/video0",
                            "video/x-h264, width=1280, height=720, framerate=30/1, format=H264",
                            "avdec_h264",
                            "videoconvert",
                            "video/x-raw, format=(string)BGR",
                            "appsink sync=false"
                            ])



# Données de départ du tag 42
mat42 = np.eye(3, 3, dtype=np.float64)
rvecs42 = np.zeros((3, 1), dtype=np.float64)
tvecs42 = np.zeros((3, 1), dtype=np.float64)

#cap = cv.VideoCapture(1)
cap = cv2.VideoCapture(pipeline, cv2.CAP_GSTREAMER)

while True:
    ret, frame = cap.read()
    #frame = cv.imread('table_jeu.png')
    if not ret:
        break

    #corrected_frame = cv.undistort(frame, camera_matrix, dist_coeffs)
    gray_frame = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)
    
    #marker_corners, marker_IDs, reject = cv.aruco.detectMarkers(gray_frame, marker_dict, parameters=param_markers)
    marker_corners, marker_IDs, reject = detector.detectMarkers(gray_frame)

    if marker_corners:
        marker_centers = []
        for ids, corners in zip(marker_IDs, marker_corners):
            #cv.polylines(corrected_frame, [corners.astype(np.int32)], True, (0, 255, 255), 4, cv.LINE_AA)
            corners = corners.reshape(4, 2)
            corners = corners.astype(int)
            topLeft, topRight, bottomRight, bottomLeft = corners


            cv.line(frame, topLeft, topRight, (0, 255, 0), 2)
            cv.line(frame, topRight, bottomRight, (0, 255, 0), 2)
            cv.line(frame, bottomRight, bottomLeft, (0, 255, 0), 2)
            cv.line(frame, bottomLeft, topLeft, (0, 255, 0), 2)

            cx = int((topLeft[0] + bottomRight[0]) / 2.0)
            cy = int((topLeft[1] + bottomRight[1]) / 2.0)
            cv.circle(frame, (cx, cy), 4, (0, 0, 255), -1)

            marker_centers.append((cx, cy))

            if len(marker_centers) > 1:
                for i in range(len(marker_centers) - 1):
                    cv.line(frame, marker_centers[i], marker_centers[i + 1], (0, 0, 255), 2)

            rvecs, tvecs, _ = aruco.estimatePoseSingleMarkers(marker_corners,taillemarker, camera_matrix, dist_coeffs) # OK
            


            for i in range(len(marker_IDs)):
                cv.drawFrameAxes(frame, camera_matrix, dist_coeffs, rvecs[i], tvecs[i], 0.03)
                print (f"id {marker_IDs[i]}", rvecs[i], tvecs[i])
                if marker_IDs[i] == 42:
                    rvecs42 = rvecs[i]
                    tvecs42 = tvecs[i]
                    mat42, _ = cv.Rodrigues(rvecs42)
                else: 
                    mat, _ = cv.Rodrigues(rvecs[i])
                    relative_position = np.dot(mat42.T, (tvecs[i].T - tvecs42.T))
                    relative_rotation = np.dot(mat42.T, mat)
                    rdest, _ = cv.Rodrigues(relative_rotation)
                    print(f"t{marker_IDs[i]}/42: {relative_position.T * 100}")  # si la valeur est fausse, multiplier par 10 au lieu de 100
                    print(f"r{marker_IDs[i]}/42: {np.degrees(rdest)}") 

            

            
            font = cv.FONT_HERSHEY_PLAIN
            cv.putText(frame, f"ID: {ids[0]}", tuple(topRight), font, 1, (0, 255, 0), 2, cv.LINE_AA)
            #print("centre tag 2D: ",marker_centers)
            



        
    cv.imshow("frame", frame)
    stop = cv.waitKey(1)
    if stop == ord("s"):
        break

#cap.release()
picam2.stop()
cv.destroyAllWindows()



